{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T14:21:14.476458Z",
     "start_time": "2025-01-27T14:21:08.042414Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install psutil",
   "id": "6eaf23bc959fbabb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psutil in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (6.1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T14:53:49.084568Z",
     "start_time": "2025-02-24T14:53:44.095705Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install tokenizers",
   "id": "51bafb8d34011f20",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tokenizers\n",
      "  Obtaining dependency information for tokenizers from https://files.pythonhosted.org/packages/44/69/d21eb253fa91622da25585d362a874fa4710be600f0ea9446d8d0217cec1/tokenizers-0.21.0-cp39-abi3-win_amd64.whl.metadata\n",
      "  Using cached tokenizers-0.21.0-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from tokenizers) (0.27.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub<1.0,>=0.16.4->tokenizers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2024.12.14)\n",
      "Using cached tokenizers-0.21.0-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "Installing collected packages: tokenizers\n",
      "Successfully installed tokenizers-0.21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2025-02-24T14:54:02.832860Z",
     "start_time": "2025-02-24T14:54:02.827273Z"
    }
   },
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig, TrainingArguments, Trainer\n",
    "from tokenizers import trainers\n",
    "from datasets import load_dataset\n",
    "from emoji import demojize\n",
    "from langdetect import detect\n",
    "import tempfile\n",
    "import torch\n",
    "import os\n",
    "import re\n",
    "import spacy\n",
    "import logging"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T13:59:02.642935Z",
     "start_time": "2025-02-24T13:59:02.636504Z"
    }
   },
   "cell_type": "code",
   "source": [
    "os.chdir(r\"C:\\Users\\Viktor\\Documents\\TMS\\NLP\\NLP_psyhology_support\")\n",
    "print(os.getcwd())"
   ],
   "id": "9eee6a22ee0d77e2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Viktor\\Documents\\TMS\\NLP\\NLP_psyhology_support\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T15:03:46.369923Z",
     "start_time": "2025-02-24T15:03:18.532734Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Загружаем оригинальный токенизатор\n",
    "# Загружаем оригинальный токенизатор\n",
    "original_tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2b\")\n",
    "\n",
    "# Загружаем токенизатор в виде объекта tokenizers\n",
    "tokenizer = original_tokenizer.backend_tokenizer\n",
    "\n",
    "# Создаём новый тренер для дообучения\n",
    "special_tokens = [original_tokenizer.unk_token, original_tokenizer.pad_token, original_tokenizer.bos_token, original_tokenizer.eos_token]\n",
    "\n",
    "trainer = trainers.BpeTrainer(show_progress=True, vocab_size=original_tokenizer.vocab_size*2, special_tokens=special_tokens)\n",
    "file_paths = [\"./data/ru_taiga-ud-train.txt\", \"./data/lt_full_corpus.txt\", \"./data/en_eslspok-ud-train.txt\"]\n",
    "\n",
    "\n",
    "# try:\n",
    "    # Обучаем токенизатор\n",
    "tokenizer.train(file_paths, trainer)\n",
    "# finally:\n",
    "#     print(f\"tmp {tmp_path} file deleting\")\n",
    "#     os.remove(tmp_path)\n",
    "# Сохраняем обновленный токенизатор\n",
    "tokenizer.save(\"gemma2_russian_tokenizer.json\")"
   ],
   "id": "73dd6ba06c374a29",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# with tempfile.NamedTemporaryFile(mode=\"w+\", delete=False, encoding=\"utf-8\") as temp_file:\n",
    "#     # Читаем данные из всех файлов и записываем их во временный файл\n",
    "#     for file_path in file_paths:\n",
    "#         try:\n",
    "#             with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "#                 temp_file.write(f.read() + \"\\n\")  # Добавляем перенос строки между файлами\n",
    "#         except UnicodeDecodeError as e:\n",
    "#             print(file_path, \"is UnicodeDecodeError\")\n",
    "#             raise e\n",
    "#     # Перемещаем указатель в начало временного файла, чтобы прочитать его содержимое\n",
    "#     temp_file.flush()\n",
    "#     tmp_path = temp_file.name\n",
    "    # Обучаем модель на корпусе"
   ],
   "id": "64332771b11a8b5c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T15:07:09.039140Z",
     "start_time": "2025-02-24T15:07:09.035211Z"
    }
   },
   "cell_type": "code",
   "source": "model_name = \"google/gemma-2-2b\"",
   "id": "86277765197f89bc",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T15:07:41.848956Z",
     "start_time": "2025-02-24T15:07:10.524799Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config = AutoConfig.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16)\n",
    "# Вывод параметров конфигурации\n"
   ],
   "id": "6ef28dbe989991eb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ce5a198d411644038c1d047e8f62f81c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T15:07:51.047672Z",
     "start_time": "2025-02-24T15:07:50.990804Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# sp = spm.SentencePieceProcessor()\n",
    "text = \"Привет, как твои дела? Labas, kaip sekasi?\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "outputs = model.generate(**inputs, max_length=50)\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ],
   "id": "ba2b6036ceae6995",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tokenizers.Tokenizer' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[39], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# sp = spm.SentencePieceProcessor()\u001B[39;00m\n\u001B[0;32m      2\u001B[0m text \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mПривет, как твои дела? Labas, kaip sekasi?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m----> 3\u001B[0m inputs \u001B[38;5;241m=\u001B[39m \u001B[43mtokenizer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_tensors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m outputs \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mgenerate(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39minputs, max_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m50\u001B[39m)\n\u001B[0;32m      5\u001B[0m generated_text \u001B[38;5;241m=\u001B[39m tokenizer\u001B[38;5;241m.\u001B[39mdecode(outputs[\u001B[38;5;241m0\u001B[39m], skip_special_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[1;31mTypeError\u001B[0m: 'tokenizers.Tokenizer' object is not callable"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T13:36:32.512053Z",
     "start_time": "2025-02-24T13:36:32.502601Z"
    }
   },
   "cell_type": "code",
   "source": "print(config)",
   "id": "45b0933273dcaff4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemma2Config {\n",
      "  \"_name_or_path\": \"google/gemma-2-2b\",\n",
      "  \"architectures\": [\n",
      "    \"Gemma2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attn_logit_softcapping\": 50.0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"cache_implementation\": \"hybrid\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"final_logit_softcapping\": 30.0,\n",
      "  \"head_dim\": 256,\n",
      "  \"hidden_act\": \"gelu_pytorch_tanh\",\n",
      "  \"hidden_activation\": \"gelu_pytorch_tanh\",\n",
      "  \"hidden_size\": 2304,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 9216,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"model_type\": \"gemma2\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 26,\n",
      "  \"num_key_value_heads\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"query_pre_attn_scalar\": 256,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"sliding_window\": 4096,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.48.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 256000\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T21:48:50.738771Z",
     "start_time": "2025-01-24T21:48:50.730793Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Кастомная конфигурация\n",
    "# \n",
    "# class Gemma2NormalizedConfigOnnx:\n",
    "#     def __init__(self, config):\n",
    "#         self.hidden_size = config.hidden_size\n",
    "#         self.num_attention_heads = config.num_attention_heads\n",
    "#         self.num_hidden_layers = config.num_hidden_layers\n",
    "#         self.vocab_size = config.vocab_size\n",
    "#         # self.max_position_embeddings = config.max_position_embeddings\n",
    "#         \n",
    "#         \n",
    "# class Gemma2OnnxConfig(OnnxConfig):\n",
    "#     NORMALIZED_CONFIG_CLASS = Gemma2NormalizedConfigOnnx\n",
    "#     @property\n",
    "#     def inputs(self) -> Mapping[str, Mapping[int, str]]:\n",
    "#         return {\"input_ids\": {0: \"batch_size\", 1: \"sequence_length\"}}\n",
    "# \n",
    "#     @property\n",
    "#     def outputs(self) -> Mapping[str, Mapping[int, str]]:\n",
    "#         return {\"logits\": {0: \"batch_size\", 1: \"sequence_length\"}}\n",
    "# \n",
    "#     @property\n",
    "#     def default_onnx_opset(self) -> int:\n",
    "#         return 14\n"
   ],
   "id": "76a3132f7276bda1",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T21:48:51.206587Z",
     "start_time": "2025-01-24T21:48:50.924562Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Экспорт модели с использованием кастомной конфигурации\n",
    "# from pathlib import Path\n",
    "# onnx_model_path =  Path(r\"C:\\Users\\Viktor\\Documents\\TMS\\NLP\\NLP_psyhology_support\\models\\gemma2\")\n",
    "# config = Gemma2OnnxConfig(config)\n",
    "# export(\n",
    "#     model=model_,\n",
    "#     config=config,\n",
    "#     output=onnx_model_path,  # Путь для сохранения ONNX модели\n",
    "#     device=\"cpu\"  # Поскольку у вас нет GPU\n",
    "# )"
   ],
   "id": "7fb7aff5c30609da",
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m onnx_model_path \u001B[38;5;241m=\u001B[39m  Path(\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mC:\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mUsers\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mViktor\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mDocuments\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mTMS\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mNLP\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mNLP_psyhology_support\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mmodels\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mgemma2\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      4\u001B[0m config \u001B[38;5;241m=\u001B[39m Gemma2OnnxConfig(config)\n\u001B[1;32m----> 5\u001B[0m \u001B[43mexport\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43monnx_model_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Путь для сохранения ONNX модели\u001B[39;49;00m\n\u001B[0;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcpu\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Поскольку у вас нет GPU\u001B[39;49;00m\n\u001B[0;32m     10\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\TMS\\NLP\\NLP_psyhology_support\\venv\\Lib\\site-packages\\optimum\\exporters\\onnx\\convert.py:888\u001B[0m, in \u001B[0;36mexport\u001B[1;34m(model, config, output, opset, device, input_shapes, disable_dynamic_axes_fix, dtype, no_dynamic_axes, do_constant_folding, model_kwargs)\u001B[0m\n\u001B[0;32m    882\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m config\u001B[38;5;241m.\u001B[39mis_torch_support_available:\n\u001B[0;32m    883\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m MinimumVersionError(\n\u001B[0;32m    884\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnsupported PyTorch version for this model. Minimum required is \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig\u001B[38;5;241m.\u001B[39mMIN_TORCH_VERSION\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    885\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m got: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtorch\u001B[38;5;241m.\u001B[39m__version__\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    886\u001B[0m         )\n\u001B[1;32m--> 888\u001B[0m     export_output \u001B[38;5;241m=\u001B[39m \u001B[43mexport_pytorch\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    889\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    890\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    891\u001B[0m \u001B[43m        \u001B[49m\u001B[43mopset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    892\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    893\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    894\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_shapes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_shapes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    895\u001B[0m \u001B[43m        \u001B[49m\u001B[43mno_dynamic_axes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mno_dynamic_axes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    896\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdo_constant_folding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdo_constant_folding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    897\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    898\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    900\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m is_tf_available() \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28missubclass\u001B[39m(\u001B[38;5;28mtype\u001B[39m(model), TFPreTrainedModel):\n\u001B[0;32m    901\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m model_kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\Documents\\TMS\\NLP\\NLP_psyhology_support\\venv\\Lib\\site-packages\\optimum\\exporters\\onnx\\convert.py:554\u001B[0m, in \u001B[0;36mexport_pytorch\u001B[1;34m(model, config, opset, output, device, input_shapes, no_dynamic_axes, do_constant_folding, model_kwargs)\u001B[0m\n\u001B[0;32m    551\u001B[0m     input_shapes \u001B[38;5;241m=\u001B[39m {}  \u001B[38;5;66;03m# will use the defaults from DEFAULT_DUMMY_SHAPES\u001B[39;00m\n\u001B[0;32m    553\u001B[0m \u001B[38;5;66;03m# Check that inputs match, and order them properly\u001B[39;00m\n\u001B[1;32m--> 554\u001B[0m dummy_inputs \u001B[38;5;241m=\u001B[39m \u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate_dummy_inputs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mframework\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43minput_shapes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    556\u001B[0m device \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mdevice(device)\n\u001B[0;32m    558\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mremap\u001B[39m(value):\n",
      "File \u001B[1;32m~\\Documents\\TMS\\NLP\\NLP_psyhology_support\\venv\\Lib\\site-packages\\optimum\\exporters\\onnx\\base.py:462\u001B[0m, in \u001B[0;36mOnnxConfig.generate_dummy_inputs\u001B[1;34m(self, framework, **kwargs)\u001B[0m\n\u001B[0;32m    460\u001B[0m \u001B[38;5;129m@add_dynamic_docstring\u001B[39m(text\u001B[38;5;241m=\u001B[39mGENERATE_DUMMY_DOCSTRING, dynamic_elements\u001B[38;5;241m=\u001B[39mDEFAULT_DUMMY_SHAPES)\n\u001B[0;32m    461\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mgenerate_dummy_inputs\u001B[39m(\u001B[38;5;28mself\u001B[39m, framework: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Dict:\n\u001B[1;32m--> 462\u001B[0m     dummy_inputs_generators \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create_dummy_input_generator_classes\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    464\u001B[0m     dummy_inputs \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m    465\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m input_name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minputs:\n",
      "File \u001B[1;32m~\\Documents\\TMS\\NLP\\NLP_psyhology_support\\venv\\Lib\\site-packages\\optimum\\exporters\\onnx\\base.py:226\u001B[0m, in \u001B[0;36mOnnxConfig._create_dummy_input_generator_classes\u001B[1;34m(self, **kwargs)\u001B[0m\n\u001B[0;32m    219\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_create_dummy_input_generator_classes\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m List[DummyInputGenerator]:\n\u001B[0;32m    220\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    221\u001B[0m \u001B[38;5;124;03m    Instantiates the dummy input generators from `self.DUMMY_INPUT_GENERATOR_CLASSES`.\u001B[39;00m\n\u001B[0;32m    222\u001B[0m \u001B[38;5;124;03m    Each dummy input generator is independent, so this method instantiates the first generator, and\u001B[39;00m\n\u001B[0;32m    223\u001B[0m \u001B[38;5;124;03m    forces the other generators to use the same batch size, meaning they will all produce inputs of the same batch\u001B[39;00m\n\u001B[0;32m    224\u001B[0m \u001B[38;5;124;03m    size. Override this method for custom behavior.\u001B[39;00m\n\u001B[0;32m    225\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 226\u001B[0m     first_inputs_gen \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDUMMY_INPUT_GENERATOR_CLASSES\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtask, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_normalized_config, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    227\u001B[0m     dummy_inputs_generators \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m    228\u001B[0m         cls_(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtask, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_normalized_config, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs) \u001B[38;5;28;01mfor\u001B[39;00m cls_ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mDUMMY_INPUT_GENERATOR_CLASSES[\u001B[38;5;241m1\u001B[39m:]\n\u001B[0;32m    229\u001B[0m     ]\n\u001B[0;32m    230\u001B[0m     dummy_inputs_generators\u001B[38;5;241m.\u001B[39minsert(\u001B[38;5;241m0\u001B[39m, first_inputs_gen)\n",
      "\u001B[1;31mIndexError\u001B[0m: tuple index out of range"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T21:49:00.879383Z",
     "start_time": "2025-01-24T21:48:54.443495Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# custom_onnx_configs={\n",
    "#     \"gemma2\": config,\n",
    "# }\n",
    "# \n",
    "# main_export(\n",
    "#     model_name,\n",
    "#     custom_onnx_configs=custom_onnx_configs,\n",
    "#     output=onnx_model_path,  # Путь для сохранения ONNX модели\n",
    "#     device=\"cpu\",\n",
    "#     trust_remote_code=True,\n",
    "#     no_post_process=True,# Поскольку у вас нет GPU\n",
    "# )"
   ],
   "id": "37ec504eb123227",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4373849e3b104d18a9ab604a3dafed2d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ONNX custom configs for: gemma2\n",
      "Submodels to export: model\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Trying to export a custom model, but could not find as many custom ONNX configs as the number of submodels to export. Please specifiy the fn_get_submodels argument, that should return a dictionary of submodules with as many items as the provided custom_export_configs dictionary.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 5\u001B[0m\n\u001B[0;32m      1\u001B[0m custom_onnx_configs\u001B[38;5;241m=\u001B[39m{\n\u001B[0;32m      2\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgemma2\u001B[39m\u001B[38;5;124m\"\u001B[39m: config,\n\u001B[0;32m      3\u001B[0m }\n\u001B[1;32m----> 5\u001B[0m \u001B[43mmain_export\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcustom_onnx_configs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcustom_onnx_configs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43monnx_model_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Путь для сохранения ONNX модели\u001B[39;49;00m\n\u001B[0;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcpu\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[43m    \u001B[49m\u001B[43mno_post_process\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[38;5;66;43;03m# Поскольку у вас нет GPU\u001B[39;49;00m\n\u001B[0;32m     12\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\TMS\\NLP\\NLP_psyhology_support\\venv\\Lib\\site-packages\\optimum\\exporters\\onnx\\__main__.py:373\u001B[0m, in \u001B[0;36mmain_export\u001B[1;34m(model_name_or_path, output, task, opset, device, dtype, fp16, optimize, monolith, no_post_process, framework, atol, cache_dir, trust_remote_code, pad_token_id, subfolder, revision, force_download, local_files_only, use_auth_token, token, for_ort, do_validation, model_kwargs, custom_onnx_configs, fn_get_submodels, use_subprocess, _variant, library_name, legacy, no_dynamic_axes, do_constant_folding, **kwargs_shapes)\u001B[0m\n\u001B[0;32m    367\u001B[0m \u001B[38;5;66;03m# The preprocessors are loaded as they may be useful to export the model. Notably, some of the static input shapes may be stored in the\u001B[39;00m\n\u001B[0;32m    368\u001B[0m \u001B[38;5;66;03m# preprocessors config.\u001B[39;00m\n\u001B[0;32m    369\u001B[0m preprocessors \u001B[38;5;241m=\u001B[39m maybe_load_preprocessors(\n\u001B[0;32m    370\u001B[0m     model_name_or_path, subfolder\u001B[38;5;241m=\u001B[39msubfolder, trust_remote_code\u001B[38;5;241m=\u001B[39mtrust_remote_code\n\u001B[0;32m    371\u001B[0m )\n\u001B[1;32m--> 373\u001B[0m \u001B[43monnx_export_from_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    374\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    375\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    376\u001B[0m \u001B[43m    \u001B[49m\u001B[43mopset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mopset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    377\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptimize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    378\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmonolith\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmonolith\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    379\u001B[0m \u001B[43m    \u001B[49m\u001B[43mno_post_process\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mno_post_process\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    380\u001B[0m \u001B[43m    \u001B[49m\u001B[43matol\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43matol\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    381\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdo_validation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdo_validation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    382\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    383\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcustom_onnx_configs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcustom_onnx_configs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    384\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfn_get_submodels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfn_get_submodels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    385\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_variant\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_variant\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    386\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlegacy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlegacy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    387\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpreprocessors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpreprocessors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    388\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    389\u001B[0m \u001B[43m    \u001B[49m\u001B[43mno_dynamic_axes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mno_dynamic_axes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    390\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    391\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_subprocess\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_subprocess\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    392\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdo_constant_folding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdo_constant_folding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    393\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs_shapes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    394\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\TMS\\NLP\\NLP_psyhology_support\\venv\\Lib\\site-packages\\optimum\\exporters\\onnx\\convert.py:1100\u001B[0m, in \u001B[0;36monnx_export_from_model\u001B[1;34m(model, output, opset, optimize, monolith, no_post_process, atol, do_validation, model_kwargs, custom_onnx_configs, fn_get_submodels, _variant, legacy, preprocessors, device, no_dynamic_axes, task, use_subprocess, do_constant_folding, **kwargs_shapes)\u001B[0m\n\u001B[0;32m   1091\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   1092\u001B[0m         model_type \u001B[38;5;129;01min\u001B[39;00m MODEL_TO_PATCH_FOR_PAST\n\u001B[0;32m   1093\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m input_name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msequence_length\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1094\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m kwargs_shapes\u001B[38;5;241m.\u001B[39mget(input_name) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1095\u001B[0m     ):\n\u001B[0;32m   1096\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1097\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExporting with a sequence length of 1 a \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_type\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m model is not supported and can yield unexpected results.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1098\u001B[0m         )\n\u001B[1;32m-> 1100\u001B[0m onnx_config, models_and_onnx_configs \u001B[38;5;241m=\u001B[39m \u001B[43m_get_submodels_and_onnx_configs\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1101\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1102\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1103\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmonolith\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmonolith\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1104\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcustom_onnx_configs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcustom_onnx_configs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mcustom_onnx_configs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1105\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcustom_architecture\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcustom_architecture\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1106\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfloat_dtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfloat_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1107\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfn_get_submodels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfn_get_submodels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1108\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpreprocessors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpreprocessors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1109\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_variant\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_variant\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1110\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlegacy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlegacy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1111\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlibrary_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlibrary_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1112\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1113\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1115\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m library_name \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdiffusers\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m   1116\u001B[0m     \u001B[38;5;66;03m# Ensure the requested opset is sufficient\u001B[39;00m\n\u001B[0;32m   1117\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m opset \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\Documents\\TMS\\NLP\\NLP_psyhology_support\\venv\\Lib\\site-packages\\optimum\\exporters\\onnx\\utils.py:205\u001B[0m, in \u001B[0;36m_get_submodels_and_onnx_configs\u001B[1;34m(model, task, monolith, custom_onnx_configs, custom_architecture, _variant, library_name, int_dtype, float_dtype, fn_get_submodels, preprocessors, legacy, model_kwargs)\u001B[0m\n\u001B[0;32m    190\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_get_submodels_and_onnx_configs\u001B[39m(\n\u001B[0;32m    191\u001B[0m     model: Union[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPreTrainedModel\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTFPreTrainedModel\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m    192\u001B[0m     task: \u001B[38;5;28mstr\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    203\u001B[0m     model_kwargs: Optional[Dict] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    204\u001B[0m ):\n\u001B[1;32m--> 205\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_get_submodels_and_export_configs\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    206\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    207\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    208\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmonolith\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    209\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcustom_onnx_configs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    210\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcustom_architecture\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    211\u001B[0m \u001B[43m        \u001B[49m\u001B[43m_variant\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    212\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlibrary_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    213\u001B[0m \u001B[43m        \u001B[49m\u001B[43mint_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    214\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfloat_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    215\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfn_get_submodels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    216\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpreprocessors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    217\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlegacy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    218\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    219\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexporter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43monnx\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    220\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\TMS\\NLP\\NLP_psyhology_support\\venv\\Lib\\site-packages\\optimum\\exporters\\utils.py:610\u001B[0m, in \u001B[0;36m_get_submodels_and_export_configs\u001B[1;34m(model, task, monolith, custom_export_configs, custom_architecture, _variant, library_name, int_dtype, float_dtype, fn_get_submodels, preprocessors, legacy, model_kwargs, exporter)\u001B[0m\n\u001B[0;32m    608\u001B[0m     logger\u001B[38;5;241m.\u001B[39merror(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mexporter\u001B[38;5;241m.\u001B[39mupper()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m custom configs for: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(custom_export_configs\u001B[38;5;241m.\u001B[39mkeys())\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    609\u001B[0m     logger\u001B[38;5;241m.\u001B[39merror(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSubmodels to export: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(submodels_for_export\u001B[38;5;241m.\u001B[39mkeys())\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 610\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    611\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTrying to export a custom model, but could not find as many custom \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mexporter\u001B[38;5;241m.\u001B[39mupper()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m configs as the number of submodels to export. Please specifiy the fn_get_submodels argument, that should return a dictionary of submodules with as many items as the provided custom_export_configs dictionary.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    612\u001B[0m     )\n\u001B[0;32m    614\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key, custom_export_config \u001B[38;5;129;01min\u001B[39;00m custom_export_configs\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m    615\u001B[0m     models_and_export_configs[key] \u001B[38;5;241m=\u001B[39m (submodels_for_export[key], custom_export_config)\n",
      "\u001B[1;31mValueError\u001B[0m: Trying to export a custom model, but could not find as many custom ONNX configs as the number of submodels to export. Please specifiy the fn_get_submodels argument, that should return a dictionary of submodules with as many items as the provided custom_export_configs dictionary."
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# # tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# inputs = tokenizer(\"Пример текста\", return_tensors=\"pt\")\n",
    "# \n",
    "# # Прогон данных через модель\n",
    "# outputs = model_(**inputs)\n",
    "# \n",
    "# # Вывод доступных выходов\n",
    "# print(outputs)"
   ],
   "id": "adbde9c9b15b0cf1"
  },
  {
   "cell_type": "code",
   "id": "1f4f8738ba0f9d49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T16:05:31.313861Z",
     "start_time": "2025-01-23T16:05:29.114638Z"
    }
   },
   "source": [
    "# # Токенизация данных\n",
    "# def tokenize_function(examples):\n",
    "#     return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=256, return_tensors=\"pt\")\n",
    "# # \n",
    "# model = ORTModelForCausalLM.from_pretrained(model_name,  export=True)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA is required but not available for bitsandbytes. Please consider installing the multi-platform enabled version of bitsandbytes, which is currently a work in progress. Please check currently supported platforms and installation instructions at https://huggingface.co/docs/bitsandbytes/main/en/installation#multi-backend\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA is required but not available for bitsandbytes. Please consider installing the multi-platform enabled version of bitsandbytes, which is currently a work in progress. Please check currently supported platforms and installation instructions at https://huggingface.co/docs/bitsandbytes/main/en/installation#multi-backend",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 9\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mtokenize_function\u001B[39m(examples):\n\u001B[0;32m      7\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m tokenizer(examples[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m\"\u001B[39m], truncation\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, padding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax_length\u001B[39m\u001B[38;5;124m\"\u001B[39m, max_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m256\u001B[39m, return_tensors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m----> 9\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mAutoModelForCausalLM\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquantization_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquantization_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\TMS\\NLP\\NLP_psyhology_support\\venv\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:564\u001B[0m, in \u001B[0;36m_BaseAutoModelClass.from_pretrained\u001B[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001B[0m\n\u001B[0;32m    562\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(config) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[0;32m    563\u001B[0m     model_class \u001B[38;5;241m=\u001B[39m _get_model_class(config, \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping)\n\u001B[1;32m--> 564\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodel_class\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    565\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mhub_kwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[0;32m    566\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    567\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    568\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnrecognized configuration class \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m for this kind of AutoModel: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    569\u001B[0m     \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModel type should be one of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(c\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mfor\u001B[39;00m\u001B[38;5;250m \u001B[39mc\u001B[38;5;250m \u001B[39m\u001B[38;5;129;01min\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping\u001B[38;5;241m.\u001B[39mkeys())\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    570\u001B[0m )\n",
      "File \u001B[1;32m~\\Documents\\TMS\\NLP\\NLP_psyhology_support\\venv\\Lib\\site-packages\\transformers\\modeling_utils.py:3620\u001B[0m, in \u001B[0;36mPreTrainedModel.from_pretrained\u001B[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001B[0m\n\u001B[0;32m   3617\u001B[0m     hf_quantizer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   3619\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m hf_quantizer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 3620\u001B[0m     \u001B[43mhf_quantizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvalidate_environment\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   3621\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtorch_dtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3622\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfrom_tf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfrom_tf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3623\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfrom_flax\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfrom_flax\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3624\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdevice_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice_map\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3625\u001B[0m \u001B[43m        \u001B[49m\u001B[43mweights_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweights_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3626\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3627\u001B[0m     torch_dtype \u001B[38;5;241m=\u001B[39m hf_quantizer\u001B[38;5;241m.\u001B[39mupdate_torch_dtype(torch_dtype)\n\u001B[0;32m   3628\u001B[0m     device_map \u001B[38;5;241m=\u001B[39m hf_quantizer\u001B[38;5;241m.\u001B[39mupdate_device_map(device_map)\n",
      "File \u001B[1;32m~\\Documents\\TMS\\NLP\\NLP_psyhology_support\\venv\\Lib\\site-packages\\transformers\\quantizers\\quantizer_bnb_8bit.py:81\u001B[0m, in \u001B[0;36mBnb8BitHfQuantizer.validate_environment\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     78\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m is_bitsandbytes_multi_backend_available\n\u001B[0;32m     80\u001B[0m bnb_multibackend_is_enabled \u001B[38;5;241m=\u001B[39m is_bitsandbytes_multi_backend_available()\n\u001B[1;32m---> 81\u001B[0m \u001B[43mvalidate_bnb_backend_availability\u001B[49m\u001B[43m(\u001B[49m\u001B[43mraise_exception\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     83\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m kwargs\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfrom_tf\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m) \u001B[38;5;129;01mor\u001B[39;00m kwargs\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfrom_flax\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m     84\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m     85\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConverting into 4-bit or 8-bit weights from tf/flax weights is currently not supported, please make\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     86\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m sure the weights are in PyTorch format.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     87\u001B[0m     )\n",
      "File \u001B[1;32m~\\Documents\\TMS\\NLP\\NLP_psyhology_support\\venv\\Lib\\site-packages\\transformers\\integrations\\bitsandbytes.py:559\u001B[0m, in \u001B[0;36mvalidate_bnb_backend_availability\u001B[1;34m(raise_exception)\u001B[0m\n\u001B[0;32m    557\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_bitsandbytes_multi_backend_available():\n\u001B[0;32m    558\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _validate_bnb_multi_backend_availability(raise_exception)\n\u001B[1;32m--> 559\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_validate_bnb_cuda_backend_availability\u001B[49m\u001B[43m(\u001B[49m\u001B[43mraise_exception\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\TMS\\NLP\\NLP_psyhology_support\\venv\\Lib\\site-packages\\transformers\\integrations\\bitsandbytes.py:537\u001B[0m, in \u001B[0;36m_validate_bnb_cuda_backend_availability\u001B[1;34m(raise_exception)\u001B[0m\n\u001B[0;32m    535\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m raise_exception:\n\u001B[0;32m    536\u001B[0m     logger\u001B[38;5;241m.\u001B[39merror(log_msg)\n\u001B[1;32m--> 537\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(log_msg)\n\u001B[0;32m    539\u001B[0m logger\u001B[38;5;241m.\u001B[39mwarning(log_msg)\n\u001B[0;32m    540\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: CUDA is required but not available for bitsandbytes. Please consider installing the multi-platform enabled version of bitsandbytes, which is currently a work in progress. Please check currently supported platforms and installation instructions at https://huggingface.co/docs/bitsandbytes/main/en/installation#multi-backend"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "7037387d2cc2b20a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-24T13:36:54.867057Z",
     "start_time": "2025-02-24T13:36:54.765440Z"
    }
   },
   "source": [
    "text = \"Hi. How are you?\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "outputs = model.generate(inputs.input_ids, max_length=50)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ],
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'bool' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m text \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mHi. How are you?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m----> 2\u001B[0m inputs \u001B[38;5;241m=\u001B[39m \u001B[43mtokenizer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_tensors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m outputs \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mgenerate(inputs\u001B[38;5;241m.\u001B[39minput_ids, max_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m50\u001B[39m)\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(tokenizer\u001B[38;5;241m.\u001B[39mdecode(outputs[\u001B[38;5;241m0\u001B[39m], skip_special_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m))\n",
      "\u001B[1;31mTypeError\u001B[0m: 'bool' object is not callable"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T15:45:09.588086Z",
     "start_time": "2025-01-27T15:36:35.744565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with torch.profiler.profile(\n",
    "    activities=[\n",
    "        torch.profiler.ProfilerActivity.CPU,\n",
    "    ],\n",
    "    on_trace_ready=torch.profiler.tensorboard_trace_handler('./log'),\n",
    "    record_shapes=True,\n",
    "    with_stack=True\n",
    ") as prof:\n",
    "    text = \"Hi. 2+2=?\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    outputs = model.generate(inputs.input_ids, max_length=50)\n",
    "    print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=50))"
   ],
   "id": "36f7a1cdf05359df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi. 2+2=?\n",
      "\n",
      "[User 0001]\n",
      "\n",
      "Hi. I'm new to this forum. I'm a 2+2 player. I'm 21 years old. I'm\n",
      "-----------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                 Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-----------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                         aten::linear         0.06%     190.791ms        98.86%      331.798s      43.169ms          7686  \n",
      "                                         aten::matmul         0.13%     438.298ms        98.74%      331.405s      42.884ms          7728  \n",
      "                                             aten::mm        98.54%      330.734s        98.55%      330.742s      43.032ms          7686  \n",
      "                                             aten::to         0.05%     153.196ms         0.25%     844.082ms      26.082us         32363  \n",
      "                                       aten::_to_copy         0.15%     493.897ms         0.21%     690.886ms      25.616us         26971  \n",
      "                   aten::scaled_dot_product_attention         0.01%      20.477ms         0.17%     575.797ms     527.287us          1092  \n",
      "    aten::_scaled_dot_product_flash_attention_for_cpu         0.14%     460.404ms         0.17%     555.320ms     508.535us          1092  \n",
      "                                           aten::mean         0.02%      83.726ms         0.14%     467.534ms     106.017us          4410  \n",
      "                                        aten::reshape         0.04%     147.155ms         0.12%     416.416ms      31.181us         13355  \n",
      "                                            aten::add         0.05%     165.533ms         0.12%     410.586ms      30.836us         13315  \n",
      "                                          aten::slice         0.07%     251.310ms         0.09%     291.169ms      10.968us         26546  \n",
      "                                      aten::transpose         0.07%     231.400ms         0.08%     278.991ms      14.961us         18648  \n",
      "                                           aten::div_         0.03%     107.176ms         0.08%     265.552ms      60.216us          4410  \n",
      "                                          aten::copy_         0.08%     264.931ms         0.08%     264.931ms       8.992us         29462  \n",
      "                                          aten::clone         0.02%      77.857ms         0.08%     259.920ms     106.263us          2446  \n",
      "                                              aten::t         0.03%     102.958ms         0.06%     207.373ms      26.981us          7686  \n",
      "                                         aten::argmax         0.06%     195.125ms         0.06%     195.252ms       4.649ms            42  \n",
      "                                            aten::mul         0.05%     181.106ms         0.06%     184.845ms      12.717us         14535  \n",
      "                                            aten::cat         0.03%     107.355ms         0.05%     171.688ms      74.324us          2310  \n",
      "                                        aten::type_as         0.01%      29.133ms         0.04%     133.680ms      30.313us          4410  \n",
      "                                           aten::gelu         0.04%     130.044ms         0.04%     130.044ms     119.088us          1092  \n",
      "                                            aten::pow         0.03%     113.689ms         0.04%     120.434ms      27.309us          4410  \n",
      "                                            aten::sum         0.03%     112.648ms         0.04%     118.946ms      26.960us          4412  \n",
      "                                     aten::as_strided         0.03%     104.617ms         0.03%     104.617ms       1.875us         55789  \n",
      "                                   aten::_unsafe_view         0.03%     100.718ms         0.03%     100.718ms      10.161us          9912  \n",
      "                                     aten::index_put_         0.01%      18.985ms         0.03%      97.256ms      44.531us          2184  \n",
      "                                  aten::empty_strided         0.03%      91.164ms         0.03%      91.164ms       3.177us         28694  \n",
      "                                           aten::view         0.03%      90.501ms         0.03%      90.501ms       5.081us         17813  \n",
      "                               aten::_index_put_impl_         0.02%      62.739ms         0.02%      78.272ms      35.839us          2184  \n",
      "                                         aten::narrow         0.01%      27.669ms         0.02%      64.333ms      14.180us          4537  \n",
      "                                     aten::empty_like         0.01%      34.419ms         0.02%      55.325ms      13.828us          4001  \n",
      "                                      aten::unsqueeze         0.01%      46.143ms         0.02%      53.573ms      11.386us          4705  \n",
      "                                          aten::where         0.01%      25.629ms         0.01%      46.052ms      42.172us          1092  \n",
      "                                     aten::contiguous         0.00%     257.300us         0.01%      40.605ms     780.867us            52  \n",
      "                                           aten::tanh         0.01%      39.127ms         0.01%      39.127ms     931.605us            42  \n",
      "                                         aten::expand         0.01%      29.311ms         0.01%      35.380ms      10.273us          3444  \n",
      "                                          aten::rsqrt         0.01%      33.914ms         0.01%      33.914ms       7.690us          4410  \n",
      "                                          aten::empty         0.01%      25.247ms         0.01%      25.247ms       3.868us          6527  \n",
      "                                            aten::neg         0.01%      20.615ms         0.01%      20.615ms       9.439us          2184  \n",
      "                                      aten::ones_like         0.00%       7.200ms         0.01%      17.641ms      32.251us           547  \n",
      "                                          aten::fill_         0.00%      13.136ms         0.00%      13.136ms       2.492us          5271  \n",
      "                                            aten::div         0.00%       6.634ms         0.00%       8.584ms     204.379us            42  \n",
      "                                           aten::tril         0.00%       7.584ms         0.00%       7.584ms      13.890us           546  \n",
      "                                   aten::resolve_conj         0.00%       7.487ms         0.00%       7.487ms       0.484us         15457  \n",
      "                                    aten::result_type         0.00%       4.839ms         0.00%       4.839ms       1.086us          4455  \n",
      "                                          aten::zero_         0.00%       1.313ms         0.00%       4.782ms      91.965us            52  \n",
      "                                      aten::embedding         0.00%       1.006ms         0.00%       4.147ms      98.740us            42  \n",
      "                                         aten::arange         0.00%       1.676ms         0.00%       2.934ms      34.931us            84  \n",
      "                                           aten::isin         0.00%       2.534ms         0.00%       2.846ms      63.238us            45  \n",
      "                                  aten::scalar_tensor         0.00%       2.794ms         0.00%       2.794ms       5.118us           546  \n",
      "-----------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 335.625s\n",
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a779f89b25cf572",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T15:00:27.371186Z",
     "start_time": "2025-01-22T14:21:54.347071Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi. 2+2=?\n",
      "\n",
      "[User 0001]\n",
      "\n",
      "Hi. I'm new to this forum. I'm a 2+2 player. I'm 21 years old. I'm\n"
     ]
    }
   ],
   "source": [
    "text = \"Hi. 2+2=?\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "outputs = model.generate(inputs.input_ids, max_length=50)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9035d590334888bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T15:33:38.082760Z",
     "start_time": "2025-01-22T15:03:32.649101Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is 2*2^5+2^8/7?\n",
      "\n",
      "[User 0001]\n",
      "\n",
      "I'm not sure how to do this problem. I know that 2^5=32 and 2\n"
     ]
    }
   ],
   "source": [
    "text = \"What is 2*2^5+2^8/7?\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "outputs = model.generate(inputs.input_ids, max_length=50)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "id": "750d214406cb366c",
   "metadata": {},
   "source": [
    "ds = load_dataset(\"devngho/culturax-mini-nonshuffled\", 'ru')\n",
    "output_dir = \"models/gemma2\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T19:34:11.765044Z",
     "start_time": "2025-01-28T19:34:11.760006Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def initialize_spacy_models():\n",
    "    \"\"\"\n",
    "    Инициализирует SpaCy модели для каждого языка.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"en\": spacy.load(\"en_core_web_sm\"),\n",
    "        \"ru\": spacy.load(\"ru_core_news_sm\"),\n",
    "        \"lt\": spacy.load(\"lt_core_news_sm\")\n",
    "    }\n",
    "\n",
    "def detect_language(text):\n",
    "    \"\"\"\n",
    "    Определяет язык текста.\n",
    "    :param text: Входной текст\n",
    "    :return: Код языка (ru, en, lt)\n",
    "    \"\"\"\n",
    "    return detect(text)\n"
   ],
   "id": "b64bd3e8bac411f3",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T19:39:29.353512Z",
     "start_time": "2025-01-28T19:39:26.820295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "spacy_models = initialize_spacy_models()\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Обработка текста: приведение к нижнему регистру, очистка, токенизация, лемматизация, удаление стоп-слов.\n",
    "    :param text: входной текст\n",
    "    :param lang: язык текста (ru, en, lt)\n",
    "    :return: список лемматизированных токенов\n",
    "    \"\"\"\n",
    "    # Приведение текста к нижнему регистру\n",
    "    text = text.lower()\n",
    "\n",
    "    # Удаление HTML-тегов\n",
    "    text = re.sub(r\"<.*?>\", \"\", text)\n",
    "\n",
    "    # Удаление эмодзи\n",
    "    text = demojize(text)\n",
    "\n",
    "    # Удаление лишних символов\n",
    "    text = re.sub(r\"[^\\w\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    \n",
    "    lang = detect_language(text)\n",
    "    # Токенизация и лемматизация\n",
    "    tokens = []\n",
    "    if lang in [\"ru\", \"en\", \"lt\"]:\n",
    "        doc = spacy_models[lang](text)\n",
    "        tokens = [\n",
    "            token.lemma_ \n",
    "            for token in doc \n",
    "            if token.text.lower() not in spacy_models[lang].Defaults.stop_words and not token.is_punct\n",
    "        ]\n",
    "        logging.info(f\"Лемматизация для языка {lang}: {tokens}\")\n",
    "\n",
    "    return tokens\n",
    "\n",
    "def tokenize_function(examples):\n",
    "        return tokenizer(examples[\"lt_text\"], padding=\"max_length\", truncation=True, max_length=128)"
   ],
   "id": "31aa3eb913910bf9",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-28T19:39:51.945587Z",
     "start_time": "2025-01-28T19:39:51.941639Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize_text(dataset, column_names=['text']):\n",
    "    for column_name in column_names:\n",
    "        for text in dataset[column_name]:\n",
    "             print(f\"Обработанный текст: {preprocess_text(text)}\")\n",
    "        print(\"-\")\n",
    "            "
   ],
   "id": "c27cc4d3f42a9cd6",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        \"\"\"\n",
    "        Инициализация кастомного датасета\n",
    "        :param dataframe: Pandas DataFrame с путями к изображениям и метками\n",
    "        :param transform: Преобразования для изображений (например, аугментации)\n",
    "        \"\"\"\n",
    "        self.dataframe = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        # Возвращаем количество элементов в датасете\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Получаем путь к изображению и метку по индексу\n",
    "        image = Image.open(io.BytesIO(self.dataframe.iloc[idx, 0]['bytes'])).convert(\"RGB\")   # столбец с путём к изображению\n",
    "        label = self.dataframe.iloc[idx, 9]\n",
    "        mask = Image.open(self.dataframe.iloc[idx, 8])\n",
    "\n",
    "        # Применяем преобразования, если они указаны\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask = self.transform(mask)\n",
    "\n",
    "        return image, mask, label"
   ],
   "id": "f8421ba1b66d46da"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,          # Папка для сохранения модели\n",
    "    evaluation_strategy=\"epoch\",  # Оценка каждые эпохи\n",
    "    learning_rate=2e-5,            # Скорость обучения\n",
    "    per_device_train_batch_size=8, # Размер батча\n",
    "    num_train_epochs=3,            # Количество эпох\n",
    "    save_steps=10_000,             # Шаги сохранения\n",
    "    save_total_limit=2,            # Максимум сохранений\n",
    "    logging_dir=\"logs\",           # Логи\n",
    "    logging_steps=500,             # Шаг логирования\n",
    "    push_to_hub=False              # Отключение публикации в Hugging Face\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                   # Модель\n",
    "    args=training_args,            # Параметры обучения\n",
    "    train_dataset=tokenized_dataset, # Тренировочные данные\n",
    "    tokenizer=tokenizer            # Токенизатор\n",
    ")"
   ],
   "id": "a043c38211e228ac"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
