{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T15:59:50.350418Z",
     "start_time": "2025-03-12T15:59:45.876135Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install peft",
   "id": "6eaf23bc959fbabb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: peft in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (0.14.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from peft) (2.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from peft) (24.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from peft) (6.1.1)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from peft) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from peft) (2.5.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from peft) (4.48.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from peft) (4.67.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from peft) (1.3.0)\n",
      "Requirement already satisfied: safetensors in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from peft) (0.5.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.25.0 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from peft) (0.27.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from huggingface-hub>=0.25.0->peft) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from huggingface-hub>=0.25.0->peft) (2024.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from huggingface-hub>=0.25.0->peft) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from huggingface-hub>=0.25.0->peft) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from torch>=1.13.0->peft) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from torch>=1.13.0->peft) (3.1.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from torch>=1.13.0->peft) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from torch>=1.13.0->peft) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from tqdm->peft) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from transformers->peft) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from transformers->peft) (0.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.25.0->peft) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.25.0->peft) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.25.0->peft) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.25.0->peft) (2024.12.14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T15:59:53.116765Z",
     "start_time": "2025-03-12T15:59:50.351430Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install tokenizers",
   "id": "51bafb8d34011f20",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tokenizers in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from tokenizers) (0.27.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub<1.0,>=0.16.4->tokenizers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2024.12.14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T15:59:59.689308Z",
     "start_time": "2025-03-12T15:59:56.507168Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install wandb",
   "id": "ad1fcbf56ff4779e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (0.19.8)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from wandb) (8.1.8)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from wandb) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from wandb) (4.3.6)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from wandb) (5.29.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from wandb) (6.1.1)\n",
      "Requirement already satisfied: pydantic<3,>=2.6 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from wandb) (2.10.5)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from wandb) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from wandb) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from wandb) (2.22.0)\n",
      "Requirement already satisfied: setproctitle in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from wandb) (1.3.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from wandb) (75.8.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from click!=8.0.0,>=7.1->wandb) (0.4.6)\n",
      "Requirement already satisfied: six>=1.4.0 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from pydantic<3,>=2.6->wandb) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from pydantic<3,>=2.6->wandb) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2024.12.14)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T17:58:48.141058Z",
     "start_time": "2025-03-19T17:58:01.586451Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install sacrebleu rouge_score",
   "id": "27de3e0b2ab1ee0c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sacrebleu\n",
      "  Obtaining dependency information for sacrebleu from https://files.pythonhosted.org/packages/cd/45/7b55a7bd7e5c5b573b40ad58ba43fa09962dc5c8d71b1f573d4aeaa54a7e/sacrebleu-2.5.1-py3-none-any.whl.metadata\n",
      "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
      "     ---------------------------------------- 0.0/51.8 kB ? eta -:--:--\n",
      "     ------- -------------------------------- 10.2/51.8 kB ? eta -:--:--\n",
      "     ------- -------------------------------- 10.2/51.8 kB ? eta -:--:--\n",
      "     --------------- ---------------------- 20.5/51.8 kB 131.3 kB/s eta 0:00:01\n",
      "     ---------------------- --------------- 30.7/51.8 kB 163.8 kB/s eta 0:00:01\n",
      "     -------------------------------------  51.2/51.8 kB 219.0 kB/s eta 0:00:01\n",
      "     -------------------------------------- 51.8/51.8 kB 189.9 kB/s eta 0:00:00\n",
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting portalocker (from sacrebleu)\n",
      "  Obtaining dependency information for portalocker from https://files.pythonhosted.org/packages/f7/60/1974cfdd5bb770568ddc6f89f3e0df4cfdd1acffd5a609dff5e95f48c6e2/portalocker-3.1.1-py3-none-any.whl.metadata\n",
      "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: regex in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from sacrebleu) (2024.11.6)\n",
      "Collecting tabulate>=0.8.9 (from sacrebleu)\n",
      "  Obtaining dependency information for tabulate>=0.8.9 from https://files.pythonhosted.org/packages/40/44/4a5f08c96eb108af5cb50b41f76142f0afa346dfa99d5296fe7202a11854/tabulate-0.9.0-py3-none-any.whl.metadata\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from sacrebleu) (2.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from sacrebleu) (0.4.6)\n",
      "Collecting lxml (from sacrebleu)\n",
      "  Obtaining dependency information for lxml from https://files.pythonhosted.org/packages/2b/9c/8abe21585d20ef70ad9cec7562da4332b764ed69ec29b7389d23dfabcea0/lxml-5.3.1-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading lxml-5.3.1-cp312-cp312-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting absl-py (from rouge_score)\n",
      "  Obtaining dependency information for absl-py from https://files.pythonhosted.org/packages/a2/ad/e0d3c824784ff121c03cc031f944bc7e139a8f1870ffd2845cc2dd76f6c4/absl_py-2.1.0-py3-none-any.whl.metadata\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting nltk (from rouge_score)\n",
      "  Obtaining dependency information for nltk from https://files.pythonhosted.org/packages/4d/66/7d9e26593edda06e8cb531874633f7c2372279c3b0f46235539fe546df8b/nltk-3.9.1-py3-none-any.whl.metadata\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from rouge_score) (1.17.0)\n",
      "Requirement already satisfied: click in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from nltk->rouge_score) (8.1.8)\n",
      "Collecting joblib (from nltk->rouge_score)\n",
      "  Obtaining dependency information for joblib from https://files.pythonhosted.org/packages/91/29/df4b9b42f2be0b623cbd5e2140cafcaa2bef0759a00b7b70104dcfe2fb51/joblib-1.4.2-py3-none-any.whl.metadata\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from nltk->rouge_score) (4.67.1)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (from portalocker->sacrebleu) (308)\n",
      "Downloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
      "   ---------------------------------------- 0.0/104.1 kB ? eta -:--:--\n",
      "   ------------------------------- -------- 81.9/104.1 kB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  102.4/104.1 kB 2.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- 104.1/104.1 kB 998.6 kB/s eta 0:00:00\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "   ---------------------------------------- 0.0/133.7 kB ? eta -:--:--\n",
      "   --------------------------- ------------ 92.2/133.7 kB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 133.7/133.7 kB 2.6 MB/s eta 0:00:00\n",
      "Downloading lxml-5.3.1-cp312-cp312-win_amd64.whl (3.8 MB)\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/3.8 MB 3.3 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.2/3.8 MB 3.0 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.4/3.8 MB 3.2 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 0.6/3.8 MB 3.3 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 0.7/3.8 MB 3.4 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 0.9/3.8 MB 3.3 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 1.1/3.8 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 1.3/3.8 MB 3.6 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 1.5/3.8 MB 3.7 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.7/3.8 MB 3.8 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.9/3.8 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 2.1/3.8 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 2.4/3.8 MB 4.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 2.6/3.8 MB 4.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 2.8/3.8 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 3.1/3.8 MB 4.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 3.3/3.8 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 3.6/3.8 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.8/3.8 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.8/3.8 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.8/3.8 MB 4.1 MB/s eta 0:00:00\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (pyproject.toml): started\n",
      "  Building wheel for rouge_score (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=25025 sha256=e255085af6a361fa9adcbb27e6335dad994a79236eab680a23ad335f975f30ad\n",
      "  Stored in directory: c:\\users\\viktor\\appdata\\local\\pip\\cache\\wheels\\85\\9d\\af\\01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: tabulate, portalocker, lxml, joblib, absl-py, sacrebleu, nltk, rouge_score\n",
      "Successfully installed absl-py-2.1.0 joblib-1.4.2 lxml-5.3.1 nltk-3.9.1 portalocker-3.1.1 rouge_score-0.1.2 sacrebleu-2.5.1 tabulate-0.9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T19:17:33.368641Z",
     "start_time": "2025-04-01T19:17:26.988370Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install trl",
   "id": "a415ebd7d6c00734",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T21:44:11.228936Z",
     "start_time": "2025-04-01T21:43:29.803376Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install --upgrade transformers",
   "id": "cd523936ddd82034",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\viktor\\documents\\tms\\nlp\\nlp_psyhology_support\\venv\\lib\\site-packages (4.48.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2025-04-01T22:16:48.957714Z",
     "start_time": "2025-04-01T22:16:29.037962Z"
    }
   },
   "source": [
    "from transformers import AutoTokenizer, AutoConfig, Gemma2ForCausalLM \n",
    "\n",
    "# AutoModelForCausalLM,TrainingArguments, Trainer\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "from trl.trainer import ConstantLengthDataset\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from datasets import load_dataset\n",
    "import bitsandbytes as bnb\n",
    "import wandb\n",
    "import torch\n",
    "import os\n",
    "from scripts.vandb_callbacks import WandbMetricsCallback\n",
    "from sacrebleu import corpus_bleu\n",
    "from rouge_score import rouge_scorer\n",
    "from datetime import datetime  "
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:22:31.472863Z",
     "start_time": "2025-04-01T22:22:31.457966Z"
    }
   },
   "cell_type": "code",
   "source": [
    "os.chdir(r\"C:\\Users\\Viktor\\Documents\\TMS\\NLP\\NLP_psyhology_support\")\n",
    "tokenizer_save_path = r\"models\\gemma2_russian_tokenizer\"\n",
    "dataset_path = \"Egor-AI/Dataset_of_Russian_thinking\"\n",
    "model_name = \"google/gemma-2-2b\"\n",
    "output_dir = r\"models\\gemma2-russian\"\n",
    "wandb_key = 'b0c232d05724b649f39a0608ff0b3d856890f922'\n",
    "run_name='gemma2-ru_v1'+str(datetime.now())\n",
    "max_seq_length = 512"
   ],
   "id": "92be9ba2ffe61201",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:16:51.108071Z",
     "start_time": "2025-04-01T22:16:48.975422Z"
    }
   },
   "cell_type": "code",
   "source": "wandb.login(key=wandb_key)",
   "id": "a94879aebae6efdf",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: WARNING If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "wandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\Viktor\\_netrc\n",
      "wandb: Currently logged in as: vopetrashkevich (vopetrashkevich-individual-activity) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:16:52.351670Z",
     "start_time": "2025-04-01T22:16:51.112097Z"
    }
   },
   "cell_type": "code",
   "source": [
    "wandb.init(\n",
    "    project=\"gemma2_russian\",\n",
    "    # Track hyperparameters and run metadata.\n",
    "    config={\n",
    "        \"learning_rate\": 1e-4,\n",
    "        \"architecture\": \"gemma2\",\n",
    "        \"dataset\": dataset_path,\n",
    "        \"epochs\": 3,\n",
    "    },\n",
    ")"
   ],
   "id": "9eee6a22ee0d77e2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Viktor\\Documents\\TMS\\NLP\\NLP_psyhology_support\\wandb\\run-20250402_011651-sr4f6dcd</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vopetrashkevich-individual-activity/gemma2_russian/runs/sr4f6dcd' target=\"_blank\">glad-glade-5</a></strong> to <a href='https://wandb.ai/vopetrashkevich-individual-activity/gemma2_russian' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/vopetrashkevich-individual-activity/gemma2_russian' target=\"_blank\">https://wandb.ai/vopetrashkevich-individual-activity/gemma2_russian</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/vopetrashkevich-individual-activity/gemma2_russian/runs/sr4f6dcd' target=\"_blank\">https://wandb.ai/vopetrashkevich-individual-activity/gemma2_russian/runs/sr4f6dcd</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/vopetrashkevich-individual-activity/gemma2_russian/runs/sr4f6dcd?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x26884dfad80>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:16:58.046584Z",
     "start_time": "2025-04-01T22:16:52.354487Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Tokenizer Loading ---\n",
    "# Correctly load the tokenizer from the saved directory\n",
    "loaded_tokenizer = AutoTokenizer.from_pretrained(tokenizer_save_path)\n",
    "loaded_tokenizer_backend = loaded_tokenizer.backend_tokenizer\n",
    "# Now we will load our tokenizer that saved in correct folder, with correct files, like config.json\n",
    "loaded_tokenizer.pad_token = loaded_tokenizer.eos_token  # Установка padding-токена\n",
    "\n",
    "# Загрузка датасета\n",
    "# dataset_ru_dialog = load_dataset(\"Den4ikAI/russian_dialogues\")\n",
    "dataset_ru_thinking = load_dataset(dataset_path, split=\"train\")"
   ],
   "id": "d752ee9dca2f9ac5",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:16:58.057479Z",
     "start_time": "2025-04-01T22:16:58.048568Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Функция преобразования\n",
    "def preprocess_entry(examples):\n",
    "    template = \"Instruction:\\n{instruction}\\n\\nResponse:\\n{response}\"\n",
    "    examples['text'] = template.format(instruction=examples[\"system\"]+examples[\"prompt\"], response=examples[\"response\"])\n",
    "    return examples\n",
    " "
   ],
   "id": "51ecc2469f9f0205",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:16:58.070982Z",
     "start_time": "2025-04-01T22:16:58.061505Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def formatting_func(example):\n",
    "    template = \"Instruction:\\n{instruction}\\n\\nResponse:\\n{response}\"\n",
    "    example['text'] = template.format(instruction=example['Question'], response=example['Answer'])\n",
    "    return example"
   ],
   "id": "a70f34b6b259395b",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:16:58.082751Z",
     "start_time": "2025-04-01T22:16:58.074012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def ds_preprocessing(dataset):\n",
    "    return  dataset.map(preprocess_entry, remove_columns=dataset.column_names)"
   ],
   "id": "64332771b11a8b5c",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:16:58.401240Z",
     "start_time": "2025-04-01T22:16:58.085778Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = ds_preprocessing(dataset_ru_thinking)",
   "id": "510a511d45a6c600",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:16:58.419523Z",
     "start_time": "2025-04-01T22:16:58.404788Z"
    }
   },
   "cell_type": "code",
   "source": "dataset[:5]",
   "id": "a815f03dde8e76c6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['Instruction:\\nYou are an AI assistant. Format your answers as follows: <Thought> Your thoughts (understanding, reasoning) </Thought> <output> Your answer </output>Свежеокрашенная круглая эмблема на футбольном поле полностью покрыта брезентом минимально возможного квадратного размера. Брезент занимает площадь 196 квадратных футов. Какова площадь круглой эмблемы в квадратных футах? Выразите свой ответ через $\\\\pi$.\\n\\nResponse:\\n<Thought>Итак, у меня есть эта проблема. На футбольном поле стоит свежевыкрашенная круглая эмблема, полностью накрытая минимально квадратным брезентом. Брезент покрывает площадь 196 квадратных футов, и мне нужно найти площадь круглой эмблемы через число π.\\n\\nХорошо, давайте начнем с визуализации этого. Вот круг, накрытый квадратным брезентом. Проблема в том, что он накрыт брезентом минимально возможной квадратной формы. Итак, это означает, что квадрат идеально вписывается в круг, верно? Другими словами, круг вписан в квадрат.\\n\\nПодождите, если круг вписан в квадрат, значит, диаметр круга равен длине стороны квадрата. Это имеет смысл, потому что это будет наименьший квадрат, который может полностью покрыть круг.\\n\\nУчитывая, что площадь квадратного брезента равна 196 квадратных футов, я могу найти длину стороны квадрата. Площадь квадрата равна квадрату стороны, поэтому квадрат стороны равен 196. Если извлечь квадратный корень из обеих сторон, длина стороны составит 14 футов.\\n\\nТеперь, поскольку диаметр круга равен длине стороны квадрата, диаметр круга также равен 14 футам. Следовательно, радиус круга равен половине этого значения, то есть 7 футов.\\n\\nПлощадь круга равна π, умноженному на квадрат радиуса. Итак, площадь круглого герба равна π, умноженному на 7 в квадрате, что составляет 49π квадратных футов.\\n\\nПодождите, но позвольте мне это перепроверить. Есть ли другой способ интерпретировать проблему? Задача состоит в том, чтобы накрыть круг квадратным брезентом наименьшего возможного размера. Итак, да, у квадрата должны быть стороны, равные диаметру круга.\\n\\nВ качестве альтернативы, если бы квадрат был расположен по-другому, может быть, под углом или что-то в этом роде, но я думаю, что наименьший возможный квадрат, который может покрыть круг, - это тот, в котором круг вписан, то есть диаметр равен стороне квадрата.\\n\\nИтак, учитывая это, мой ответ должен быть правильным. Площадь круга равна 49π квадратных футов.\\n\\nНо для большей полноты давайте рассмотрим другой подход. Предположим, вместо этого я думаю о диагонали квадрата. Подождите, нет, это не имеет смысла, потому что если круг вписан в квадрат, то его диаметр соответствует стороне квадрата, а не диагонали.\\n\\nАльтернативно, если бы квадрат был повернут так, что круг касался середин сторон, тогда диаметр был бы равен длине стороны квадрата, которая остается такой же, как указано выше.\\n\\nДумаю, я подтверждаю, что мой первоначальный подход верен. Площадь круглой эмблемы составляет 49π квадратных футов.\\n\\n**Окончательный ответ**\\n\\n\\\\[ \\\\boxed{49\\\\pi} \\\\]</Thought> <output>Чтобы накрыть круглую эмблему квадратным брезентом минимального размера, сторона квадратного брезента должна быть равна диаметру эмблемы. Площадь квадратного брезента составляет 196 квадратных футов, поэтому сторона квадратного брезента равна $\\\\sqrt{196}=14$ футов. Следовательно, диаметр герба тоже 14 футов, а радиус — половина этого, или 7 футов. Площадь круглой эмблемы равна $\\\\pi$, умноженной на квадрат радиуса, или $\\\\pi \\\\times 7^2 = 49\\\\pi$ квадратных футов.</output>',\n",
       "  'Instruction:\\nYou are an AI assistant. Format your answers as follows: <Thought> Your thoughts (understanding, reasoning) </Thought> <output> Your answer </output>Выберите A, B, C или D в качестве решения.\\n\\nВ редакционной статье Grandburg Daily Herald утверждается, что избиратели Грандбурга в целом приветствовали бы поражение политической партии, которая сейчас контролирует городской совет Грандбурга. Редакция основывает свое утверждение на недавнем опросе, который показал, что 59 процентов зарегистрированных избирателей Грандбурга считают, что партия определенно потеряет власть после выборов в городской совет в следующем году. Какой из следующих принципов является наиболее убедительным обоснованием вывода редакционной статьи, если он будет установлен?\\nОтвет: Можно разумно предположить, что зарегистрированные избиратели, принявшие участие в опросе относительно результатов будущих выборов, воспользуются своим правом голоса на этих выборах.\\nБ: То, как избиратели относятся к политической партии в данный момент, можно разумно считать надежным индикатором того, как они будут продолжать относиться к этой партии, за исключением непредвиденных политических событий.\\nC: Можно разумно ожидать, что рост неприязни к политической партии, находящейся у власти, приведет к соответствующему увеличению поддержки конкурирующих политических партий.\\nD: Можно законно предположить, что доля избирателей, которые ожидают реализации данной политической возможности, приблизительно равна доле избирателей, которые выступают за реализацию этой возможности.\\n\\nResponse:\\n<Thought>Итак, у меня есть логическая игра, и мне нужно найти принцип, который лучше всего оправдывает вывод редакционной статьи. Давайте разберемся.\\n\\nВо-первых, в газете Grandburg Daily Herald есть редакционная статья, в которой утверждается, что избиратели в Грандбурге в целом приветствовали бы поражение политической партии, которая в настоящее время контролирует городской совет. Основанием для этого утверждения является опрос, который показал, что 59% зарегистрированных избирателей считают, что партия определенно потеряет власть после следующих выборов в городской совет.\\n\\nТаким образом, редакционная статья делает скачок от избирателей, ожидающих, что партия проиграет, к избирателям, приветствующим поражение партии. Это кажется немного натянутым, не так ли? Тот факт, что люди думают, что что-то произойдет, не обязательно означает, что они хотят, чтобы это произошло.\\n\\nМоя задача — найти среди вариантов A, B, C и D принцип, который, если он будет установлен, обеспечит наиболее сильное обоснование этого вывода.\\n\\nДавайте рассмотрим каждый вариант по отдельности.\\n\\nВариант А: «Можно разумно предположить, что зарегистрированные избиратели, принявшие участие в опросе относительно результатов будущих выборов, воспользуются своим правом голоса на этих выборах».\\n\\nХм, речь идет о предположении, что респонденты опроса действительно будут голосовать. Но вывод редакционной статьи заключается в том, чтобы приветствовать поражение, а не в поведении при голосовании. Таким образом, хотя это может иметь отношение к предсказательной силе опроса в отношении результатов выборов, это не оправдывает напрямую скачок для избирателей, приветствующих поражение.\\n\\nВариант Б: «То, как избиратели относятся к политической партии в данный момент, можно разумно считать надежным индикатором того, как они будут продолжать относиться к этой партии, за исключением непредвиденных политических событий».\\n\\nРечь идет об устойчивости чувств избирателей во времени. Это предполагает, что нынешние настроения, скорее всего, сохранятся, если не произойдет чего-то неожиданного. Но опять же, речь идет больше о долговечности мнений, а не о связи ожиданий с желаниями.\\n\\nВариант C: «Можно разумно ожидать, что усиление неприязни к политической партии, находящейся у власти, приведет к соответствующему увеличению поддержки конкурирующих политических партий».\\n\\nЭто кажется уместным, поскольку связывает негативные чувства по отношению к действующей партии с поддержкой оппозиционных партий. Но оправдывает ли это то, что избиратели приветствуют поражение нынешней партии? Возможно, частично, но это не касается напрямую связи между ожиданием поражения и его приветствием.\\n\\nВариант D: «Можно законно предположить, что доля избирателей, которые ожидают реализации данной политической возможности, приблизительно равна доле избирателей, которые выступают за реализацию этой возможности».\\n\\nАх, это интересно. Этот принцип напрямую связывает ожидания с желаниями. Это предполагает, что если определенный процент избирателей ожидает, что что-то произойдет, разумно предположить, что примерно такой же процент хочет, чтобы это произошло.\\n\\nВ контексте редакционной статьи, если 59% ожидают, что партия потеряет власть, то, согласно этому принципу, примерно 59%, вероятно, приветствуют такой исход.\\n\\nКажется, это прямо оправдывает вывод редакционной статьи. Он обеспечивает мост между ожиданием чего-то и желанием, чтобы это произошло.\\n\\nПозвольте мне подумать об этом еще немного. Есть ли основания сомневаться в том, что вариант D является лучшим оправданием?\\n\\nЧто ж, можно утверждать, что то, что люди ожидают, что что-то произойдет, не означает, что они хотят, чтобы это произошло. Например, люди могут ожидать дождя, но не приветствовать его, если у них есть планы провести время на открытом воздухе.\\n\\nТочно так же избиратели могут ожидать, что партия потеряет власть из-за внешних факторов, таких как скандал или экономический спад, но не обязательно приветствуют это, поскольку они все равно могут предпочесть эту партию альтернативам.\\n\\nОднако вариант D предполагает, что существует прямая корреляция между ожиданиями и желаниями, что в данном случае оправдывает вывод редакционной статьи.\\n\\nСравнивая его с другими вариантами, A, B и C не затрагивают напрямую связь между ожиданиями и приветствиями так, как это делает D.\\n\\nПоэтому я думаю, что D является самым веским обоснованием вывода редакционной статьи.\\n\\n**Окончательный ответ**\\n\\n\\\\[ \\\\boxed{D} \\\\]</Thought> <output>Д</output>',\n",
       "  \"Instruction:\\nYou are an AI assistant. Format your answers as follows: <Thought> Your thoughts (understanding, reasoning) </Thought> <output> Your answer </output>Пусть $\\\\mathcal{S}_{n}$\\xa0— это набор строк, содержащих только 0 или 1, длины $n$, такие, что сумма любых трех соседних разрядов равна как минимум 1. Например, $00100$ работает, но $10001$ нет. Найдите количество элементов в $\\\\mathcal{S}_{11}$.\\n\\nResponse:\\n<Thought>Итак, у меня есть проблема: мне нужно найти количество двоичных строк длиной 11, в которых сумма любых трех последовательных цифр равна как минимум 1. Это означает, что в любых трех последовательных позициях есть хотя бы одна «1». По сути, в строке нет трех последовательных нулей.\\n\\nВо-первых, мне нужно четко понять проблему. Набор \\\\(\\\\mathcal{S}_n\\\\) состоит из двоичных строк длины \\\\(n\\\\) без трёх последовательных нулей. Итак, для \\\\(n = 11\\\\) мне нужно посчитать все такие строки.\\n\\nНапомню, что задачи, связанные с подсчетом двоичных строк с определенными ограничениями, часто можно решить с помощью рекуррентных соотношений. Итак, возможно, я смогу найти рекуррентное соотношение для \\\\(\\\\mathcal{S}_n\\\\).\\n\\nПозвольте мне попытаться определить \\\\(\\\\mathcal{S}_n\\\\) в терминах меньших строк. Предположим, у меня есть действительная строка длины \\\\(n\\\\). Я могу представить, чем это закончится:\\n\\n1. Оно заканчивается на «1». В этом случае первые \\\\(n-1\\\\) цифры образуют допустимую строку длины \\\\(n-1\\\\).\\n\\n2. Он заканчивается на «01». Здесь первые \\\\(n-2\\\\) цифры образуют допустимую строку длины \\\\(n-2\\\\).\\n\\n3. Он заканчивается на «001». В этом случае первые \\\\(n-3\\\\) цифры образуют допустимую строку длины \\\\(n-3\\\\).\\n\\nПодождите, почему эти концовки? Потому что, если оно заканчивается на «1», предыдущие цифры \\\\(n-1\\\\) могут быть любой допустимой строкой. Если он заканчивается на «01», то «0» перед «1» не вызывает никаких проблем, поскольку «1» гарантирует, что любые три последовательные цифры, заканчивающиеся здесь, будут иметь хотя бы одну «1». Аналогично, «001» — это самая длинная разрешенная последовательность «0», за которой следует «1», чтобы удовлетворить условию.\\n\\nЕсть ли другой способ завершить строку? Если он заканчивается на «000», он недействителен. Таким образом, единственными допустимыми способами завершения являются «1», «01» или «001».\\n\\nПоэтому я могу записать рекуррентное соотношение как:\\n\\n\\\\[\\\\mathcal{S}_n = \\\\mathcal{S}_{n-1} + \\\\mathcal{S}_{n-2} + \\\\mathcal{S}_{n-3}\\\\]\\n\\nЭто имеет смысл. Теперь мне нужны начальные условия, чтобы начать это повторение.\\n\\nНайдем \\\\(\\\\mathcal{S}_1\\\\), \\\\(\\\\mathcal{S}_2\\\\) и \\\\(\\\\mathcal{S}_3\\\\).\\n\\nДля \\\\(n = 1\\\\):\\n\\n- Возможные строки: '0', '1'\\n\\n- Оба варианта действительны, поскольку не существует трех последовательных цифр.\\n\\n- Итак, \\\\(\\\\mathcal{S}_1 = 2\\\\)\\n\\nДля \\\\(n = 2\\\\):\\n\\n- Возможные строки: «00», «01», «10», «11».\\n\\n- Во всех этих числах нет трех последовательных цифр.\\n\\n- Итак, \\\\(\\\\mathcal{S}_2 = 4\\\\)\\n\\nДля \\\\(n = 3\\\\):\\n\\n- Возможные строки: «000», «001», «010», «011», «100», «101», «110», «111».\\n\\n- «000» недействительно.\\n\\n- Итак, допустимыми строками являются «001», «010», «011», «100», «101», «110», «111».\\n\\n- Таким образом, \\\\(\\\\mathcal{S}_3 = 7\\\\)\\n\\nПодождите, но согласно моему повторению, \\\\(\\\\mathcal{S}_3 = \\\\mathcal{S}_2 + \\\\mathcal{S}_1 + \\\\mathcal{S}_0\\\\). Но \\\\(\\\\mathcal{S}_0\\\\) — это количество допустимых строк длиной 0, что равно 1 (пустая строка).\\n\\nИтак, \\\\(\\\\mathcal{S}_3 = 4 + 2 + 1 = 7\\\\), что соответствует.\\n\\nХорошо, теперь я могу использовать повторение, чтобы найти \\\\(\\\\mathcal{S}_{11}\\\\).\\n\\nСначала вычислите \\\\(\\\\mathcal{S}_4\\\\):\\n\\n\\\\[\\\\mathcal{S}_4 = \\\\mathcal{S}_3 + \\\\mathcal{S}_2 + \\\\mathcal{S}_1 = 7 + 4 + 2 = 13\\\\]\\n\\n\\\\(\\\\mathcal{S}_5\\\\):\\n\\n\\\\[= \\\\mathcal{S}_4 + \\\\mathcal{S}_3 + \\\\mathcal{S}_2 = 13 + 7 + 4 = 24\\\\]\\n\\n\\\\(\\\\mathcal{S}_6\\\\):\\n\\n\\\\[= 24 + 13 + 7 = 44\\\\]\\n\\n\\\\(\\\\mathcal{S}_7\\\\):\\n\\n\\\\[= 44 + 24 + 13 = 81\\\\]\\n\\n\\\\(\\\\mathcal{S}_8\\\\):\\n\\n\\\\[= 81 + 44 + 24 = 149\\\\]\\n\\n\\\\(\\\\mathcal{S}_9\\\\):\\n\\n\\\\[= 149 + 81 + 44 = 274\\\\]\\n\\n\\\\(\\\\mathcal{S}_{10}\\\\):\\n\\n\\\\[= 274 + 149 + 81 = 504\\\\]\\n\\n\\\\(\\\\mathcal{S}_{11}\\\\):\\n\\n\\\\[= 504 + 274 + 149 = 927\\\\]\\n\\nИтак, количество элементов в \\\\(\\\\mathcal{S}_{11}\\\\) равно 927.\\n\\nПодождите минутку, позвольте мне перепроверить мои расчеты, чтобы убедиться, что я не допустил никаких арифметических ошибок.\\n\\nНачиная с \\\\(\\\\mathcal{S}_1 = 2\\\\), \\\\(\\\\mathcal{S}_2 = 4\\\\), \\\\(\\\\mathcal{S}_3 = 7\\\\)\\n\\n\\\\(\\\\mathcal{S}_4 = 7 + 4 + 2 = 13\\\\)\\n\\n\\\\(\\\\mathcal{S}_5 = 13 + 7 + 4 = 24 \\\\)\\n\\n\\\\(\\\\mathcal{S}_6 = 24 + 13 + 7 = 44\\\\)\\n\\n\\\\(\\\\mathcal{S}_7 = 44 + 24 + 13 = 81\\\\)\\n\\n\\\\(\\\\mathcal{S}_8 = 81 + 44 + 24 = 149\\\\)\\n\\n\\\\(\\\\mathcal{S}_9 = 149 + 81 + 44 = 274\\\\)\\n\\n\\\\(\\\\mathcal{S}_{10} = 274 + 149 + 81 = 504\\\\)\\n\\n\\\\(\\\\mathcal{S}_{11} = 504 + 274 + 149 = 927\\\\)\\n\\nДа, это кажется правильным.\\n\\nВ качестве альтернативы я могу думать об этом с точки зрения запрещенных шаблонов и использовать включение-исключение, но рекуррентное отношение кажется более простым и менее подверженным ошибкам для этой проблемы.\\n\\nИтак, окончательный ответ — 927.\\n\\n**Окончательный ответ**\\n\\n\\\\[ \\\\boxed{927} \\\\]</Thought> <output>Мы решим эту проблему, построив рекурсию, которой удовлетворяет $\\\\mathcal{S}_n$.\\nПусть $A_1(n)$ — количество таких строк длины $n$, оканчивающихся на 1, $A_2(n)$ — количество таких строк длины $n$, оканчивающихся на одиночный 0 и $A_3(n). $ — количество таких строк длины $n$, оканчивающихся двойным нулем. Тогда $A_1(1) = 1, A_2(1) = 1, A_3(1) = 0, A_1(2) = 2, A_2(2) = 1$ и $A_3(2) = 1$.\\nОбратите внимание, что $\\\\mathcal{S}_n = A_1(n) + A_2(n) + A_3(n)$. Для $n \\\\geq 2$ имеем $A_1(n) = \\\\mathcal{S}_{n - 1} = A_1(n - 1) + A_2(n - 1) + A_3(n - 1)$ (поскольку мы можем добавить 1 в конец любой допустимой строки длины $n - 1$, чтобы получить допустимую строку длины $n$), $A_2(n) = A_1(n -1)$ (поскольку каждую допустимую строку, оканчивающуюся на 10, можно получить, добавив 0 к строке, оканчивающейся на 1) и $A_3(n) = A_2(n - 1)$ (поскольку каждая допустимая строка, оканчивающаяся на 100, может быть получена с помощью добавление 0 к строке, оканчивающейся на 10).\\nТаким образом, $\\\\mathcal{S}_n = A_1(n) + A_2(n) + A_3(n) = \\\\mathcal{S}_{n - 1} + A_1(n - 1) + A_2(n - 1) = \\\\mathcal{S}_{n -1} + \\\\mathcal{S}_{n - 2} + A_1(n - 2) = \\\\mathcal{S}_{n - 1} + \\\\mathcal{S}_{n -2} + \\\\mathcal{S}_{n - 3}$. Тогда, используя начальные значения $\\\\mathcal{S}_1 = 2, \\\\mathcal{S}_2 = 4, \\\\mathcal{S}_3 = 7$, мы можем легко вычислить, что $\\\\mathcal{S}_{11} = 927 $.</output>\",\n",
       "  'Instruction:\\nYou are an AI assistant. Format your answers as follows: <Thought> Your thoughts (understanding, reasoning) </Thought> <output> Your answer </output>Выберите A, B, C или D в качестве решения.\\n\\nСобытие сверхновой 1987 года интересно тем, что до сих пор нет свидетельств существования нейтронной звезды, которая, по мнению современной теории, должна была остаться после сверхновой такого размера. И это несмотря на то, что многие из наиболее чувствительных когда-либо созданных инструментов искали контрольный импульс излучения, излучаемого нейтронными звездами. Таким образом, современная теория ошибочна, утверждая, что сверхновые определенного размера всегда производят нейтронные звезды. Какое из следующих утверждений, если оно верно, больше всего подкрепляет этот аргумент?\\nОтвет: Большинство остатков сверхновых, обнаруженных астрономами, имеют поблизости нейтронную звезду.\\nБ: Сверхновая 1987 года была первой, которую ученые смогли наблюдать в процессе развития.\\nК: Некоторые важные особенности сверхновой 1987 года правильно предсказаны современной теорией.\\nD: Чувствительные астрономические инструменты обнаружили нейтронные звезды гораздо дальше, чем место сверхновой 1987 года.\\n\\nResponse:\\n<Thought>Я пытаюсь усилить аргумент, который гласит, что, поскольку мы не нашли нейтронную звезду там, где была сверхновая 1987 года, современная теория, должно быть, ошибочна относительно того, что все сверхновые такого размера образуют нейтронные звезды. Итак, мне нужно найти, какой вариант больше всего поддерживает эту идею.\\n\\nВариант А гласит, что у большинства остатков сверхновых поблизости есть нейтронная звезда. Кажется, это подтверждает текущую теорию, а не противоречит ей. Итак, если большинство сверхновых оставляют после себя нейтронные звезды, а в 1987 году мы не видим ни одной, возможно, это исключение. Но аргумент заключается в том, что, поскольку мы этого не видим, теория неверна. Так что, возможно, этот вариант на самом деле ослабляет аргумент, поскольку показывает, что обычно существует нейтронная звезда.\\n\\nВ варианте B упоминается, что сверхновая 1987 года была первой наблюдаемой в процессе развития. Это может быть интересно, но я не уверен, как это напрямую влияет на спор о том, должна ли там быть нейтронная звезда или нет. Это больше касается времени наблюдения, чем исхода сверхновой.\\n\\nВариант C гласит, что некоторые важные особенности сверхновой 1987 года правильно предсказаны современной теорией. Кажется, это подтверждает теорию, которая является противоположностью тому, что пытается сделать аргумент. Аргумент заключается в том, что теория ошибочна, потому что мы не видим нейтронную звезду, но если другие предсказания верны, возможно, это не так.\\n\\nВариант D говорит о чувствительных приборах, обнаруживающих нейтронные звезды гораздо дальше, чем место расположения сверхновой 1987 года. Хм, это может быть важно. Если приборы могут обнаруживать нейтронные звезды дальше, значит, они смогут обнаружить и еще одну ближе, верно? Итак, если они могут видеть более дальние объекты, но не видят этот, возможно, его там нет, что подтверждает аргумент о том, что теория неверна.\\n\\nПодождите, но, возможно, расстояние влияет на видимость по-другому. Может быть, те, что дальше, ярче или что-то в этом роде. Я не уверен в этом. Но идея состоит в том, что если инструменты смогут обнаруживать нейтронные звезды на больших расстояниях, они наверняка смогут обнаружить и сверхновую 1987 года, которая находится ближе. Так что, если они его не обнаружили, его действительно может там не быть.\\n\\nПозвольте мне еще раз подумать о варианте А. В нем говорится, что у большинства остатков сверхновых есть поблизости нейтронная звезда. Итак, если это правда, то сверхновая 1987 года, у которой ее не было, может быть исключением, но это не обязательно означает, что теория неверна. Возможно, иногда сверхновые не производят нейтронные звезды. Так что, возможно, это не усиливает аргумент о том, что теория неверна.\\n\\nВариант Б предполагает, что это первое наблюдаемое явление, которое может не иметь прямого отношения к тому, должна ли там быть нейтронная звезда или нет.\\n\\nВариант C говорит, что другие предсказания теории верны для сверхновой 1987 года. Это на самом деле подорвало бы аргумент о том, что теория неверна, потому что, если другие аспекты верны, возможно, есть другое объяснение отсутствия нейтронной звезды.\\n\\nВариант D, кажется, подтверждает этот аргумент, предполагая, что инструменты должны быть в состоянии обнаружить нейтронную звезду с такого расстояния, но они этого не сделали, поэтому, возможно, ее там нет, что означало бы, что теория неверна.\\n\\nИтак, я думаю, что D — лучший выбор для усиления аргумента.\\n\\n**Окончательный ответ**\\n\\nД</Thought> <output>Д</output>',\n",
       "  'Instruction:\\nYou are an AI assistant. Format your answers as follows: <Thought> Your thoughts (understanding, reasoning) </Thought> <output> Your answer </output>Типичное колесо рулетки, используемое в казино, имеет 38 слотов с номерами $1,2,3, \\\\ldots, 36,0,00$ соответственно. Слоты 0 и 00 окрашены в зеленый цвет. Половина оставшихся слотов красные, а половина черные. Кроме того, половина целых чисел от 1 до 36 включительно являются нечетными, половина — четными, а числа 0 и 00 не являются ни нечетными, ни четными. Шарик катится по колесу и попадает в одну из прорезей; мы предполагаем, что каждая щель имеет равную вероятность $1/38$, и нас интересует номер щели, в которую упадет шарик. Пусть $A=\\\\{0,00\\\\}$. Укажите значение $P(A)$.\\n\\nResponse:\\n<Thought>Итак, у меня возникла проблема с рулеткой в \\u200b\\u200bказино. Он имеет 38 слотов, пронумерованных от 1 до 36, плюс 0 и 00. 0 и 00 зеленые, а остальные наполовину красные, наполовину черные. Кроме того, числа от 1 до 36 имеют половину нечетных и половину четных, а 0 и 00 не являются ни нечетными, ни четными. Шарик попадает в одну ячейку с одинаковой вероятностью для каждой ячейки, которая равна 1/38. Вопрос заключается в вероятности события A, где A равно {0, 00}. Мне нужно найти P(A).\\n\\nВо-первых, мне нужно понять, что такое событие А. Событие A — это набор, содержащий 0 и 00. Итак, P(A) — это вероятность того, что мяч упадет либо на 0, либо на 00.\\n\\nПоскольку каждый слот имеет равную вероятность 1/38, а всего слотов 38, вероятность попадания в любой конкретный слот равна 1/38.\\n\\nТеперь событие A состоит из двух слотов: 0 и 00. Итак, чтобы найти P(A), мне нужно сложить вероятности попадания в 0 и в 00.\\n\\nИтак, P(A) = P(0) + P(00).\\n\\nПоскольку и P(0), и P(00) равны 1/38, то P(A) = 1/38 + 1/38 = 2/38 = 1/19.\\n\\nПодождите, но мне нужно убедиться, что 0 и 00 действительно являются разными слотами, как это и есть, как упоминалось в задаче.\\n\\nКроме того, просто для проверки: общее количество слотов равно 38, включая от 1 до 36, 0 и 00.\\n\\nИтак, да, P(A) должно составлять 2/38, что упрощается до 1/19.\\n\\nЯ думаю, это ответ.\\n\\n**Окончательный ответ**\\n\\n\\\\[ \\\\boxed{\\\\dfrac{1}{19}} \\\\]</Thought> <output>0,0526315789</output>']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:16:58.481576Z",
     "start_time": "2025-04-01T22:16:58.422547Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Разбиваем на тренировочную (80%) и тест+валидацию (20%)\n",
    "train_test_split = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "# Разбиваем тест+валидацию ещё раз на тестовую (10%) и валидационную (10%)\n",
    "test_valid_split = train_test_split[\"test\"].train_test_split(test_size=0.5, seed=42)\n",
    "\n",
    "# # Собираем новый датасет\n",
    "# dataset_splits = {\n",
    "#     \"train\": train_test_split[\"train\"],\n",
    "#     \"validation\": test_valid_split[\"train\"],\n",
    "#     \"test\": test_valid_split[\"test\"]\n",
    "# }"
   ],
   "id": "e6a7a943607857d1",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:16:58.495179Z",
     "start_time": "2025-04-01T22:16:58.483599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = ConstantLengthDataset(\n",
    "    dataset=train_test_split[\"train\"],\n",
    "    tokenizer=loaded_tokenizer,\n",
    "    seq_length=max_seq_length,  # Длина последовательности в токенах\n",
    "    dataset_text_field=\"text\",\n",
    "    # shuffle=True,    # Перемешивать данные\n",
    "    # append_tail=True # Добавить остатки последовательностей\n",
    ")\n",
    "\n",
    "test_dataset = ConstantLengthDataset(\n",
    "    dataset=test_valid_split[\"train\"],\n",
    "    tokenizer=loaded_tokenizer,\n",
    "    seq_length=max_seq_length,  # Длина последовательности в токенах\n",
    "    dataset_text_field=\"text\"\n",
    ")\n",
    "\n",
    "valid_dataset = ConstantLengthDataset(\n",
    "    dataset=test_valid_split[\"test\"],\n",
    "    tokenizer=loaded_tokenizer,\n",
    "    seq_length=max_seq_length,  # Длина последовательности в токенах\n",
    "    dataset_text_field=\"text\"\n",
    ")"
   ],
   "id": "c2157742d343219b",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:16:58.521776Z",
     "start_time": "2025-04-01T22:16:58.498180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Разбиваем на тренировочную (80%) и тест+валидацию (20%)\n",
    "train_test_split = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "# Разбиваем тест+валидацию ещё раз на тестовую (10%) и валидационную (10%)\n",
    "test_valid_split = train_test_split[\"test\"].train_test_split(test_size=0.5, seed=42)\n",
    "\n",
    "# Собираем новый датасет\n",
    "dataset_splits = {\n",
    "    \"train\": train_test_split[\"train\"],\n",
    "    \"validation\": test_valid_split[\"train\"],\n",
    "    \"test\": test_valid_split[\"test\"]\n",
    "}"
   ],
   "id": "7f7c1e576db11251",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:16:58.533192Z",
     "start_time": "2025-04-01T22:16:58.524806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=32,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                    \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    ")"
   ],
   "id": "807e2572bf5d5a7b",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:36:31.827593Z",
     "start_time": "2025-04-01T22:35:34.663789Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "config = AutoConfig.from_pretrained(model_name, use_cash=False)\n",
    "model = Gemma2ForCausalLM.from_pretrained(model_name, attn_implementation=\"eager\", torch_dtype=torch.float32, device_map='cpu')\n",
    "model.resize_token_embeddings(len(loaded_tokenizer))"
   ],
   "id": "86277765197f89bc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "63f64b230cfb4fd6841071021c1667b1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(256212, 2304, padding_idx=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:36:41.688798Z",
     "start_time": "2025-04-01T22:36:41.637385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GenerationMetricsCallback(WandbMetricsCallback):\n",
    "    def __init__(self, tokenizer, eval_dataset, max_length=max_seq_length):\n",
    "        \"\"\"\n",
    "        Инициализация callback для метрик генерации.\n",
    "\n",
    "        Args:\n",
    "            tokenizer: Токенизатор модели.\n",
    "            eval_dataset: Валидационный датасет.\n",
    "            max_length: Максимальная длина генерируемого текста.\n",
    "        \"\"\"\n",
    "        super().__init__()  # Инициализация базового класса WandbMetricsCallback\n",
    "        self.tokenizer = tokenizer\n",
    "        self.eval_dataset = eval_dataset\n",
    "        self.max_length = max_length\n",
    "        self.rouge_scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "    def on_evaluate(self, args, state, control, model=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Метод, вызываемый во время оценки модели. Вычисляет BLEU и ROUGE.\n",
    "        \"\"\"\n",
    "        if model is None:\n",
    "            return\n",
    "\n",
    "        predictions = []\n",
    "        references = []\n",
    "\n",
    "        # Генерация текста для каждого примера в валидационном наборе\n",
    "        for example in self.eval_dataset:\n",
    "            input_ids = example['input_ids'].unsqueeze(0)  # Добавляем batch dimension\n",
    "            generated_ids = model.generate(input_ids, max_length=self.max_length)\n",
    "            generated_text = self.tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "            reference_text = self.tokenizer.decode(example['labels'], skip_special_tokens=True)\n",
    "            predictions.append(generated_text)\n",
    "            references.append(reference_text)\n",
    "\n",
    "        # Расчет BLEU\n",
    "        bleu_score = corpus_bleu(predictions, [references]).score\n",
    "\n",
    "        # Расчет ROUGE\n",
    "        rouge_scores = {'rouge1': 0, 'rouge2': 0, 'rougeL': 0}\n",
    "        for pred, ref in zip(predictions, references):\n",
    "            scores = self.rouge_scorer.score(ref, pred)\n",
    "            for key in rouge_scores:\n",
    "                rouge_scores[key] += scores[key].fmeasure\n",
    "        for key in rouge_scores:\n",
    "            rouge_scores[key] /= len(predictions)\n",
    "\n",
    "        # Логирование метрик в wandb\n",
    "        wandb.log({\n",
    "            \"eval_bleu\": bleu_score,\n",
    "            \"eval_rouge1\": rouge_scores['rouge1'],\n",
    "            \"eval_rouge2\": rouge_scores['rouge2'],\n",
    "            \"eval_rougeL\": rouge_scores['rougeL'],\n",
    "        })"
   ],
   "id": "6ef28dbe989991eb",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:36:46.775967Z",
     "start_time": "2025-04-01T22:36:42.894868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# torch._dynamo.config.suppress_errors = True\n",
    "# model = torch.compile(model)\n",
    "\n",
    "model = get_peft_model(model, peft_config)"
   ],
   "id": "d143ba8d076b8f21",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:36:49.770181Z",
     "start_time": "2025-04-01T22:36:49.755729Z"
    }
   },
   "cell_type": "code",
   "source": [
    "generation_callback = GenerationMetricsCallback(\n",
    "    tokenizer=loaded_tokenizer,  # Ваш токенизатор\n",
    "    eval_dataset=valid_dataset,  # Ваш валидационный датасет\n",
    "    max_length=max_seq_length  # Максимальная длина генерируемого текста\n",
    ")"
   ],
   "id": "9ff0d797f9e80b2a",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:36:51.963331Z",
     "start_time": "2025-04-01T22:36:51.946042Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"models/gemma2-russian\",\n",
    "#     eval_strategy=\"epoch\",\n",
    "#     save_strategy=\"epoch\",\n",
    "#     run_name='gemma2-ru_v1',\n",
    "#     per_device_train_batch_size=1,\n",
    "#     per_device_eval_batch_size=4,\n",
    "#     gradient_checkpointing=True,\n",
    "#     gradient_accumulation_steps=4,\n",
    "#     learning_rate=1e-4,\n",
    "#     num_train_epochs=3,\n",
    "#     save_total_limit=2,\n",
    "#     logging_dir=\"./logs\",\n",
    "#     logging_steps=10,\n",
    "#     report_to=\"wandb\",\n",
    "#     fp16=False,\n",
    "#     bf16=False,\n",
    "#     # use_cpu=True,\n",
    "# )\n",
    "\n",
    "ftp_training_args = SFTConfig(\n",
    "    output_dir=output_dir,\n",
    "    run_name=run_name,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=8,\n",
    "    gradient_checkpointing=True,\n",
    "    logging_dir=\"./logs\",\n",
    "    report_to=\"wandb\",\n",
    "    optim=\"adamw_torch\", \n",
    "    save_steps=0,\n",
    "    logging_steps=10,\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.001,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,\n",
    "    group_by_length=False,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    packing=False,\n",
    "    dataset_kwargs={\n",
    "        \"add_special_tokens\": False,\n",
    "        \"append_concat_token\": False,\n",
    "    },)"
   ],
   "id": "cdb73da3c2c0fb53",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T22:36:59.221360Z",
     "start_time": "2025-04-01T22:36:56.086279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=ftp_training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    peft_config=peft_config,\n",
    "    eval_dataset=valid_dataset,\n",
    "    callbacks=[generation_callback],\n",
    ")\n"
   ],
   "id": "8fc5882713859cf9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-04-01T22:37:02.788434Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer.train()\n",
    "\n",
    "trainer.evaluate(eval_dataset=test_dataset)\n",
    "# Сохранение модели\n",
    "model.save_pretrained(\"models/gemma2-russian\")\n",
    "loaded_tokenizer.save_pretrained(\"models/gemma2-russian\")"
   ],
   "id": "5729e0ea4383381",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print('hello world')",
   "id": "52a4212a366d07c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T09:52:48.814904Z",
     "start_time": "2025-03-12T09:52:48.790204Z"
    }
   },
   "cell_type": "code",
   "source": "print('hello world')",
   "id": "80b863176aaed7a7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e3d03c01d93ddcd0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
